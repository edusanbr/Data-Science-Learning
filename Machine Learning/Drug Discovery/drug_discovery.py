# -*- coding: utf-8 -*-
"""Drug Discovery.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HPFVtGEJc-xwKSE2Vae7BS6nkYX6wKqk

# **Bioinformatics Project - Computational Drug Discovery **



---

## **Download PaDEL-Descriptor**
"""

! wget https://github.com/dataprofessor/bioinformatics/raw/master/padel.zip
! wget https://github.com/dataprofessor/bioinformatics/raw/master/padel.sh

! unzip padel.zip

"""## **Load bioactivity data**"""

import pandas as pd

df3 = pd.read_csv('acetylcholinesterase_04_bioactivity_data_3class_pIC50.csv')

df3

selection = ['canonical_smiles','molecule_chembl_id']
df3_selection = df3[selection]
df3_selection.to_csv('molecule.smi', sep='\t', index=False, header=False)

! cat molecule.smi | head -5

! cat molecule.smi | wc -l

"""## **Calculate fingerprint descriptors**

### **Calculate PaDEL descriptors**
"""

! cat padel.sh

! bash padel.sh

! ls -l

"""## **Preparing the X and Y Data Matrices**

### **X data matrix**
"""

df3_X = pd.read_csv('descriptors_output.csv')

df3_X

df3_X = df3_X.drop(columns=['Name'])
df3_X

"""## **Y variable**

### **Convert IC50 to pIC50**
"""

df3_Y = df3['pIC50']
df3_Y

"""## **Combining X and Y variable**"""

dataset3 = pd.concat([df3_X,df3_Y], axis=1)
dataset3

dataset3.to_csv('acetylcholinesterase_06_bioactivity_data_3class_pIC50_pubchem_fp.csv', index=False)

"""# **Regression Models with Random Forest**

## **Load bioactivity data**

## **1. Import libraries**
"""

import pandas as pd
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor

"""## **2. Load the data set**"""

df = pd.read_csv('acetylcholinesterase_06_bioactivity_data_3class_pIC50_pubchem_fp.csv')

"""## **3. Input features**

### **3.1. Input features**
"""

X = df.drop('pIC50', axis=1)
X

"""### **3.2. Output features**"""

Y = df.pIC50
Y

"""### **3.3. Let's examine the data dimension**"""

X.shape

Y.shape

"""### **3.4. Remove low variance features**"""

from sklearn.feature_selection import VarianceThreshold
selection = VarianceThreshold(threshold=(.8 * (1 - .8)))
X = selection.fit_transform(X)

X.shape

from sklearn.feature_selection import SelectKBest, f_regression
selector = SelectKBest(f_regression, k=100)  # Mant√©m as 100 melhores features
X_train_new = selector.fit_transform(X_train, Y_train)
X_test_new = selector.transform(X_test)

"""## **4. Data split (80/20 ratio)**"""

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)

X_train_new.shape, Y_train.shape

X_test_new.shape, Y_test.shape

"""Remove irrelevant descriptors"""

from sklearn.feature_selection import SelectKBest, f_regression
selector = SelectKBest(f_regression, k=100)  # Mant√©m as 100 melhores features
X_train_new = selector.fit_transform(X_train, Y_train)
X_test_new = selector.transform(X_test)

"""## **5. Building a Regression Model using Random Forest**"""

model = RandomForestRegressor(n_estimators=100)
model.fit(X_train_new, Y_train)
r2 = model.score(X_test_new, Y_test)
r2

Y_pred = model.predict(X_test_new)

"""## **6. Scatter Plot of Experimental vs Predicted pIC50 Values**"""

import seaborn as sns
import matplotlib.pyplot as plt

# Configura√ß√µes do estilo do Seaborn
sns.set(color_codes=True)
sns.set_style("white")

# Criar o gr√°fico de regress√£o
ax = sns.regplot(x=Y_test, y=Y_pred, scatter_kws={'alpha': 0.4})

# Configura√ß√µes dos r√≥tulos e limites do gr√°fico
ax.set_xlabel('Experimental pIC50', fontsize='large', fontweight='bold')
ax.set_ylabel('Predicted pIC50', fontsize='large', fontweight='bold')
ax.set_xlim(0, 12)
ax.set_ylim(0, 12)
ax.figure.set_size_inches(5, 5)

# Exibir o gr√°fico
plt.show()

"""Top 10 compounds"""

from sklearn.pipeline import Pipeline

# Carregar os dados originais (com SMILES e IDs)
df_original = pd.read_csv('acetylcholinesterase_04_bioactivity_data_3class_pIC50.csv')
df_descriptors = pd.read_csv('acetylcholinesterase_06_bioactivity_data_3class_pIC50_pubchem_fp.csv')

# Combinar os dados mantendo as colunas essenciais
df_completo = pd.concat([
    df_original[['molecule_chembl_id', 'canonical_smiles']],
    df_descriptors.drop('pIC50', axis=1),
    df_descriptors['pIC50']
], axis=1)

#  Pr√©-processamento completo
X = df_completo.drop(['molecule_chembl_id', 'canonical_smiles', 'pIC50'], axis=1)
y = df_completo['pIC50']

# Aplicar os mesmos filtros usados no treino
X = selection.transform(X)  # VarianceThreshold
X = selector.transform(X)   # SelectKBest

# Fazer as predi√ß√µes
df_completo['pIC50_predito'] = model.predict(X)

# Selecionar os top 10 compostos
top_10 = df_completo.sort_values('pIC50_predito', ascending=False)[
    ['molecule_chembl_id', 'canonical_smiles', 'pIC50', 'pIC50_predito']
].head(10)

print("\nüíä Top 10 Compostos Mais Promissores:")
print(top_10.to_markdown(index=False, tablefmt="grid"))

"""# **Comparing Regressors**


Comparing several ML algorithms for build regression models of acetylcholinesterase inhibitors.

## **1. Import libraries**
"""

! pip install lazypredict

import pandas as pd
import seaborn as sns
from sklearn.model_selection import train_test_split
import lazypredict
from lazypredict.Supervised import LazyRegressor

"""## **2. Load the data set**

"""

df = pd.read_csv('acetylcholinesterase_06_bioactivity_data_3class_pIC50_pubchem_fp.csv')

X = df.drop('pIC50', axis=1)
Y = df.pIC50

"""## **3. Data pre-processing**"""

# Examine X dimension
X.shape

# Remove low variance features
from sklearn.feature_selection import VarianceThreshold
selection = VarianceThreshold(threshold=(.8 * (1 - .8)))
X = selection.fit_transform(X)
X.shape

# Perform data splitting using 80/20 ratio
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

"""## **4. Compare ML algorithms**"""

# Defines and builds the lazyclassifier
clf = LazyRegressor(verbose=0,ignore_warnings=True, custom_metric=None)
models_train,predictions_train = clf.fit(X_train, X_train, Y_train, Y_train)
models_test,predictions_test = clf.fit(X_train, X_test, Y_train, Y_test)

# Performance table of the training set (80% subset)
predictions_train

# Performance table of the test set (20% subset)
predictions_test

"""## **5. Data visualization of model performance**"""

# Bar plot of R-squared values
import matplotlib.pyplot as plt
import seaborn as sns

#train["R-Squared"] = [0 if i < 0 else i for i in train.iloc[:,0] ]

plt.figure(figsize=(5, 10))
sns.set_theme(style="whitegrid")
ax = sns.barplot(y=predictions_train.index, x="R-Squared", data=predictions_train)
ax.set(xlim=(0, 1))

# Bar plot of RMSE values
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(5, 10))
sns.set_theme(style="whitegrid")
ax = sns.barplot(y=predictions_train.index, x="RMSE", data=predictions_train)
ax.set(xlim=(0, 10))

# Bar plot of calculation time
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(5, 10))
sns.set_theme(style="whitegrid")
ax = sns.barplot(y=predictions_train.index, x="Time Taken", data=predictions_train)
ax.set(xlim=(0, 10))