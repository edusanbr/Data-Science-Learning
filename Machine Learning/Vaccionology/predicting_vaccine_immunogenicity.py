# -*- coding: utf-8 -*-
"""Predicting vaccine immunogenicity.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SGmQY1zCsY9HxGC8AcMd5jhPurVmnj6u

# Preparação dos dados
"""

# -*- coding: utf-8 -*-
"""ML para predição de resposta imune a vacina 2 .ipynb

Versão otimizada com:
- Balanceamento de classes
- Otimização de hiperparâmetros
- Métricas estendidas
"""

import numpy as np
import pandas as pd

#configuração
n_paciente =100
np.random.seed(42)

#Genes selecionados com base em vias imunes
genes_imunes = {'IFNG': 'Resposta a interferon', 'TNF':'Inflamação',
                'IL6': 'Ativaçã Imune','IL10':'Regulação Imune','TLR4': 'Resposta a LPS',
                'CD4': 'Células T helper', 'STAT1': 'Via JAK-STAT',
                'TGFB1': 'Imunossupressão',    'JAK2': 'Via JAK-STAT',
                'VEGFA': 'Controle (não imune)'}

#High-responders: expressão aumentada de genes pró-inflamatórios
dados_high = np.random.lognormal(mean=1.5, sigma=0.5, size=(50, len(genes_imunes)))
dados_high[:,[0,1,2,5]] *=1.5 #IFGN, TNF, IL6, CD4

#Low-responders: expressão aumentada de genes regulatórios
dados_low = np.random.lognormal(mean=1.5, sigma=0.5, size=(50, len(genes_imunes)))
dados_low[:, [3, 7]] *= 1.5  # IL10, TGFB1

#Combinar dados
X = np.vstack([dados_high, dados_low])
y = np.array([1]*50 + [0]*50)

# DataFrame
df = pd.DataFrame(X, columns=genes_imunes.keys())
df['response'] = y

print(X.shape)

df

"""# Análise Exploratória"""

import seaborn as sns
import matplotlib.pyplot as plt

# 1. Distribuição de genes-chave
plt.figure(figsize=(12, 6))
sns.boxplot(data=df.melt(id_vars='response'), x='variable', y='value', hue='response')
plt.xticks(rotation=45)
plt.title('Distribuição de Expressão Gênica por Resposta')
plt.show()

# 2. Correlação entre genes
plt.figure(figsize=(10, 8))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
plt.title('Matriz de Correlação')
plt.show()

"""# Modelagem com validação cruzada"""

# ============== CÉLULA MODIFICADA ==============
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import make_pipeline
from sklearn.model_selection import cross_validate, StratifiedKFold, GridSearchCV
from sklearn.metrics import make_scorer, f1_score, precision_score, recall_score
from sklearn.ensemble import RandomForestClassifier


# Pipeline com balanceamento
pipeline = make_pipeline(
    SMOTE(random_state=42),
    RandomForestClassifier(random_state=42)
)

# Métricas originais
scoring = {
    'f1': make_scorer(f1_score),
    'precision': make_scorer(precision_score),
    'recall': make_scorer(recall_score),
    'accuracy': 'accuracy'
}

# Validação cruzada
cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)

# Busca de hiperparâmetros
param_grid = {
    'randomforestclassifier__n_estimators': [100, 200],
    'randomforestclassifier__max_depth': [None, 10, 20],
    'randomforestclassifier__class_weight': [{0: 1, 1: 3}, 'balanced']  # Peso 3x para Classe 1
}

grid_search = GridSearchCV(pipeline, param_grid, cv=cv, scoring=scoring, refit='f1', return_train_score=True)
grid_search.fit(X, y)

# Resultados
print("\n=== MÉTRICAS ORIGINAIS ===")
print(f"F1-score médio (validação): {grid_search.cv_results_['mean_test_f1'][grid_search.best_index_]:.2f}")
print(f"Acurácia média (validação): {grid_search.cv_results_['mean_test_accuracy'][grid_search.best_index_]:.2f}")
print(f"Precisão média (validação): {grid_search.cv_results_['mean_test_precision'][grid_search.best_index_]:.2f}")
print(f"Recall médio (validação): {grid_search.cv_results_['mean_test_recall'][grid_search.best_index_]:.2f}")

# Melhor modelo
modelo = grid_search.best_estimator_
print("\nMelhores parâmetros:", grid_search.best_params_)

"""# Interpretação do modelo

Features
"""

#Treinar modelo final
modelo.fit(X,y)

# Acessar o RandomForest DENTRO do pipeline
rf_modelo = modelo.named_steps['randomforestclassifier']

# Importância dos genes (agora acessando o modelo correto)
importancias = pd.DataFrame({
    'Gene': df.columns[:-1],
    'Importancia': rf_modelo.feature_importances_  # <-- Acesso correto
}).sort_values('Importancia', ascending=False)

print("\nImportância dos Genes (Modelo Otimizado):")
print(importancias.head(10))

# Plot de importância
plt.figure(figsize=(10, 5))
plt.barh(importancias['Gene'], importancias['Importancia'], color='#1f77b4')
plt.xlabel('Importância')
plt.title('Top Genes Preditores (SHAP Values)')
plt.gca().invert_yaxis()  # Mostra o mais importante no topo
plt.tight_layout()
plt.show()

"""SHAP Values"""

import shap
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

# 1. Configuração segura do explainer
try:
    if hasattr(rf_modelo, 'named_steps'):
        rf_modelo = modelo.named_steps['randomforestclassifier']
    else:
        rf_modelo = modelo

    explainer = shap.TreeExplainer(rf_modelo)
    shap_values = explainer.shap_values(X)

    # Para classificação binária
    if isinstance(shap_values, list):
        shap_values = shap_values[1]  # Usamos a classe positiva (High)

except Exception as e:
    print(f"Erro ao calcular SHAP values: {str(e)}")
    raise

# 2. Cálculo seguro da importância (garantindo array 1D)
try:
    # Método 100% garantido para arrays multidimensionais
    shap_means = [np.abs(shap_values[:,i]).mean() for i in range(shap_values.shape[1])]

    shap_df = pd.DataFrame({
        'Gene': list(genes_imunes.keys()),
        'Importância_SHAP': shap_means
    }).sort_values('Importância_SHAP', ascending=True)

except Exception as e:
    print(f"Erro ao criar DataFrame: {str(e)}")
    raise

# 3. Visualização garantida
plt.figure(figsize=(10, 0.6 * len(shap_df)))
plt.barh(shap_df['Gene'], shap_df['Importância_SHAP'], color='#1f77b4')
plt.title('Importância dos Genes (Média dos Valores SHAP Absolutos)', fontsize=14)
plt.xlabel('Média |SHAP value| → Maior valor = maior impacto', fontsize=12)
plt.grid(axis='x', alpha=0.3)
plt.tight_layout()

# Adiciona valores nas barras
for index, value in enumerate(shap_df['Importância_SHAP']):
    plt.text(value, index, f' {value:.3f}', va='center')

plt.show()

# Calcular SHAP values
explainer = shap.TreeExplainer(rf_modelo)
shap_values = explainer(X)
shap_values_class1 = shap_values[:, :, 1].values  # Classe positiva (binária)


# Plotar com personalização
plt.figure(figsize=(8, 6))  # Tamanho ajustável
shap.summary_plot(
    shap_values_class1,
    X,
    feature_names=list(genes_imunes.keys()),  # Nomes das features (genes)
    show=False,  # Para evitar plot duplicado
    plot_type="dot",  # Tipo beeswarm
    color=plt.get_cmap("coolwarm"),  # Escala de cores (azul/vermelho)
    alpha=0.7  # Transparência dos pontos
)

# Ajustar eixos e labels (como na imagem)
plt.xlim(-0.2, 0.2)  # Limites do eixo X
plt.xlabel("SHAP value (impact on model output)", fontsize=12)
plt.gca().set_ylabel("Genes", fontsize=12)  # Rótulo Y

# Remover bordas desnecessárias (opcional)
plt.gca().spines['top'].set_visible(False)
plt.gca().spines['right'].set_visible(False)

plt.tight_layout()  # Evitar cortes
plt.show()

"""# Validação externa"""

# Fixar a semente aleatória para reprodutibilidade
np.random.seed(42)

# Criar dataset de validação externa
X_val = np.random.lognormal(mean=1.3, sigma=0.6, size=(30, len(genes_imunes)))
y_val = np.random.choice([0, 1], size=30, p=[0.5, 0.5])

#  Aplicar modelo
y_pred = modelo.predict(X_val)

#  Métricas
from sklearn.metrics import classification_report
print(classification_report(y_val, y_pred))

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

cm = confusion_matrix(y_val, y_pred)
disp = ConfusionMatrixDisplay(cm, display_labels=['Low', 'High'])
disp.plot(cmap='Blues')
plt.title('Matriz de Confusão - Validação Externa')
plt.show()

"""# Análise de vias biológica"""

# Usar os top 5 genes do modelo
top_genes = importancias['Gene'].head(5).tolist()

# Verificar enriquecimento em vias (exemplo simplificado)
vias = {
    'Resposta_Interferon': ['IFNG', 'STAT1', 'JAK2'],
    'Inflamação': ['TNF', 'IL6', 'TLR4']
}

print("Genes top em vias imunes:")
for via, genes in vias.items():
    print(f"{via}: {set(top_genes) & set(genes)}")

"""# Documentação de Reproducibilidade"""

#salvar modelo
import joblib
joblib.dump(modelo, 'modelo_vacinacao.pkl')

#exportar resultados
df.to_csv('dados_simulados.csv', index=False)
importancias.to_csv('importancia_genes.csv', index=False)# Nova seção